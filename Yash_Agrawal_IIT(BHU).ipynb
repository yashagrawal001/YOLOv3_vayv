{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rb8yUmE16d5",
        "outputId": "b665865b-a211-4c9a-be3c-6c5951891f5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flyr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f928i7vXKvNw",
        "outputId": "9ae6d3e5-936f-4bb2-a5d4-0f81cd1bbf2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flyr in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from flyr) (1.25.2)\n",
            "Requirement already satisfied: nptyping==0.3.1 in /usr/local/lib/python3.10/dist-packages (from flyr) (0.3.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from flyr) (9.4.0)\n",
            "Requirement already satisfied: typish in /usr/local/lib/python3.10/dist-packages (from nptyping==0.3.1->flyr) (1.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from skimage import color, draw\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import flyr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "FxPWfaSwcO8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "\n",
        "# Load pre-trained YOLOv3 model\n",
        "model = load_model('/content/drive/MyDrive/full_yolo_backend.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QprGueo94rOI",
        "outputId": "f01fe164-7113-44cd-d4ae-037e17ec8d39"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_paths(directory):\n",
        "    dataset_paths = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.json'):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            dataset_paths.append(filepath)\n",
        "    return dataset_paths\n",
        "\n",
        "# Function to get mask from annotation data\n",
        "def get_mask_from_annotation_data(annotation_data, shape=(512, 640)):\n",
        "    mask = np.zeros(shape, dtype='int16')\n",
        "    for index, corner_points in enumerate(annotation_data['corners'], start=1):\n",
        "        polygon = np.array([[coords['y'], coords['x']] for coords in corner_points])\n",
        "        instance_mask = draw.polygon2mask(shape, polygon)\n",
        "        mask[instance_mask] = index\n",
        "    return mask\n",
        "\n",
        "# Function to visualize image with mask\n",
        "def visualize_image_with_mask(image_path, annotation_path):\n",
        "    thermogram = flyr.unpack(image_path)\n",
        "    annotation_data = get_annotation_data(annotation_path)\n",
        "    mask = get_mask_from_annotation_data(annotation_data)\n",
        "    masked_image = color.label2rgb(mask, thermogram.render(palette='grayscale'))\n",
        "\n",
        "    _, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "    im = ax[0].imshow(thermogram.celsius, cmap='inferno')\n",
        "    cax = make_axes_locatable(ax[0]).append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    plt.colorbar(im, cax=cax, values=np.unique(thermogram.celsius), label='Temperature (ºC)')\n",
        "    ax[0].set_title('Thermography image')\n",
        "    ax[0].set_axis_off()\n",
        "\n",
        "    ax[1].imshow(masked_image)\n",
        "    ax[1].set_title('Masked image')\n",
        "    ax[1].set_axis_off()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Function to define and train the model\n",
        "def train_model(images_paths, annotations_paths):\n",
        "    # Load pre-trained YOLOv3 model\n",
        "    yolo_model = load_model('/content/drive/MyDrive/full_yolo_backend.h5')\n",
        "\n",
        "    # Freeze convolutional layers\n",
        "    for layer in yolo_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Extract features from YOLOv3 model\n",
        "    features = yolo_model.output\n",
        "    # print(\"hello\")\n",
        "    # print(\"features: \",features[1])\n",
        "\n",
        "    # Add custom classification layers\n",
        "    x = GlobalAveragePooling2D()(features[1])\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=yolo_model.input, outputs=output)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "    # Split data into train and validation sets\n",
        "    train_images_paths, val_images_paths, train_annotations_paths, val_annotations_paths = \\\n",
        "        train_test_split(images_paths, annotations_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define callbacks\n",
        "    checkpoint_path = 'model_checkpoint.keras'\n",
        "    checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, verbose=1)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        generator(train_images_paths, train_annotations_paths),\n",
        "        steps_per_epoch=len(train_images_paths),\n",
        "        epochs=10,\n",
        "        validation_data=generator(val_images_paths, val_annotations_paths),\n",
        "        validation_steps=len(val_images_paths),\n",
        "        callbacks=[checkpoint_callback]\n",
        "    )\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# Function to generate batches of training data\n",
        "def generator(images_paths, annotations_paths, batch_size=32):\n",
        "    while True:\n",
        "        for i in range(0, len(images_paths), batch_size):\n",
        "            batch_images_paths = images_paths[i:i+batch_size]\n",
        "            batch_annotations_paths = annotations_paths[i:i+batch_size]\n",
        "            X_batch = []\n",
        "            y_batch = []\n",
        "            for img_path, ann_path in zip(batch_images_paths, batch_annotations_paths):\n",
        "                thermogram = flyr.unpack(img_path)\n",
        "                annotation_data = get_annotation_data(ann_path)\n",
        "                mask = get_mask_from_annotation_data(annotation_data)\n",
        "                X_batch.append(thermogram.celsius)\n",
        "                y_batch.append(1 if np.sum(mask) > 0 else 0)  # Label 1 if defect present, else 0\n",
        "            yield np.array(X_batch)[:, :, :, np.newaxis], np.array(y_batch)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Define the path to the dataset\n",
        "    DATA_PATH = '/content/drive/MyDrive/dataset_1'\n",
        "\n",
        "    # Load dataset paths\n",
        "    images_paths = load_dataset_paths(\"/content/drive/MyDrive/dataset_1/images\")\n",
        "    annotations_paths = load_dataset_paths(\"/content/drive/MyDrive/dataset_1/annotations\")\n",
        "\n",
        "\n",
        "    # # Visualize an example image with mask\n",
        "    # example_image_path = images_paths[0]\n",
        "    # example_annotation_path = annotations_paths[0]\n",
        "    # visualize_image_with_mask(example_image_path, example_annotation_path)\n",
        "\n",
        "    # Train the model\n",
        "    model, history = train_model(images_paths, annotations_paths)\n",
        "\n",
        "    # Plot training history\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "_-_dncNb2JtN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "S2KCfaiqQU9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}